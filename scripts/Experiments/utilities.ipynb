{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abfdef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "import classla\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c678b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - name of a text file with one sentence per line\n",
    "# output - list of sentences (strings)\n",
    "def read_file_as_list_of_sentences(input_file_name):\n",
    "    with open(input_file_name, \"r\") as input_file:\n",
    "        return input_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3669e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - list of sentences (strings) and a classla pipeline (POS tokenize or tokenize)\n",
    "# output - list of dictionaries ((POS) tokenized sentences) \n",
    "def run_through_classla_pipeline(list_of_sentences, pipeline):\n",
    "    return [pipeline(sentence).to_dict()[0][0] for sentence in list_of_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651555ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - list of dictionaries (a dictionary for each word - the tokenized version of the sentence)\n",
    "# output - list of dictionaries (dictionaries that contain punctuation one after another are squashed into one)\n",
    "def squash_punctuation(sentence):\n",
    "    new_sentence = []\n",
    "\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i]['text'] in ',()\"[];.?!:-':\n",
    "            if len(new_sentence) > 0 and all(character in ',()\"[];.?!:-' for character in new_sentence[-1]['text']):\n",
    "                new_sentence[-1]['text'] += sentence[i]['text']\n",
    "            else:\n",
    "                new_sentence.append(sentence[i])\n",
    "        else:\n",
    "            new_sentence.append(sentence[i])\n",
    "            \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42da702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - label (string)\n",
    "# output - transformed label (string) - one that is part of the allowed labels\n",
    "def transform_label(label):\n",
    "    label_priorities = {1: ',', 2: '?', 3: '!', 4: '.', 5: ':',\n",
    "                        6: '-', 7: ';', 8: '(', 9: ')', 10: '\"',\n",
    "                        11: '...', 12: '[', 13: ']'}\n",
    "    \n",
    "    allowed_labels = [',', '?', '!', '.', ':', '-', ';', '(', ')', '\"',\n",
    "                      '', '[', ']', '...', '\",', '),', '\".', ').', ':\"']\n",
    "    \n",
    "    matched_label = next((allowed_label for allowed_label in allowed_labels[13:] if allowed_label in label),\n",
    "                         False)\n",
    "\n",
    "    \n",
    "    if label in allowed_labels:\n",
    "        return label\n",
    "    elif matched_label:\n",
    "        return matched_label\n",
    "    else:\n",
    "        for i in range(1, 14):\n",
    "            if label_priorities[i] in label:\n",
    "                return label_priorities[i]\n",
    "    \n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5274e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence and an index of a word (dictionary) - assigns a label to each word based on the punctuation after\n",
    "# output - a label - None for punctuation, punctuation for words followed by punctuation and empty for words if they are not\n",
    "def word2label(sentence, i):\n",
    "    if all(character in ',()\"[];.?!:-' for character in sentence[i]['text']):\n",
    "        return None\n",
    "\n",
    "    if i < len(sentence) - 1:\n",
    "        if all(character in ',()\"[];.?!:-' for character in sentence[i+1]['text']):\n",
    "            label = transform_label(sentence[i+1]['text'])\n",
    "            return label\n",
    "    \n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d73191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries)\n",
    "# output - list of labels (strings) with None labels for punctuation being filtered out\n",
    "def sent2labels(sentence):\n",
    "    return [label for label in (word2label(sentence, i) for i in range(len(sentence))) if label != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957a8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - list of dictionaries (a dictionary for each word - the tokenized version of the sentence)\n",
    "# output - new sentence (string) with the punctuation removed\n",
    "def remove_punctuation(sentence):\n",
    "    new_sentence = ''\n",
    "\n",
    "    for i in range(len(sentence)):\n",
    "        if all(character in ',()\"[];.?!:-' for character in sentence[i]['text']):\n",
    "            pass\n",
    "        else:\n",
    "            new_sentence = new_sentence + sentence[i]['text'] + ' '\n",
    "    \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7fef0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries)\n",
    "# output - True/False depending on whether the sentence contains interrogative word or not\n",
    "def contains_interrogative_word(sentence):\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i]['xpos'].startswith('Pi'):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65110e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries)\n",
    "# output - True/False depending on whether the sentence contains interrogative particle or not\n",
    "def contains_interrogative_particle(sentence):\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i]['xpos'] == 'Ti':\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc80bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries)\n",
    "# output - True/False depending on whether the sentence contains imperative verb or not\n",
    "def contains_imperative_verb(sentence):\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i]['xpos'][0] == 'V' and sentence[i]['xpos'][4] == 'z':\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef93cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries) and index of a word (dictionary)\n",
    "# output - True/False depending on whether the sentence contains relative pronoun before and the tag\n",
    "#          of the pronoun in the sentence (returns '' if False)\n",
    "def contains_relative_pronoun_before(sentence, i):\n",
    "    for word_i in reversed(range(len(sentence[:i]))):\n",
    "        if sentence[word_i]['xpos'].startswith('Pr'):\n",
    "            return True, sentence[word_i]['xpos']\n",
    "    \n",
    "    return False, ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "244b362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries) and index of a word (dictionary)\n",
    "# output - True/False depending on whether the sentence contains conjunction before and the tag\n",
    "#          of the conjunction in the sentence (returns '' if False)\n",
    "def contains_conj_before(sentence, i):\n",
    "    for word_i in reversed(range(len(sentence[:i]))):\n",
    "        if sentence[word_i]['xpos'].startswith('C'):\n",
    "            return True, sentence[word_i]['xpos']\n",
    "    \n",
    "    return False, ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d372051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries) and index of a word (dictionary)\n",
    "# output - True/False depending on whether the sentence contains repetitive word before and the tag\n",
    "#          of the word in the sentence (returns '' if False)\n",
    "def contains_repetitive_word_before(sentence, i):\n",
    "    for word_i in reversed(range(len(sentence[:i]))):\n",
    "        if i < len(sentence)-1 and sentence[word_i]['text'].lower() == sentence[i+1]['text'].lower():\n",
    "            return True, sentence[word_i]['xpos']\n",
    "    \n",
    "    return False, ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c51ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries) and index of a word (dictionary)\n",
    "# output - the count of the verbs before the word\n",
    "def count_of_verbs_before(sentence, i):\n",
    "    verbs_count = 0\n",
    "\n",
    "    for word_i in range(len(sentence[:i])):\n",
    "        if sentence[word_i]['upos'] == 'VERB':\n",
    "            verbs_count += 1\n",
    "    \n",
    "    return verbs_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4cc7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xpos(xpos, word='word'):\n",
    "    def gender_number_article(number, gender, article):\n",
    "        gender_number_article = ''\n",
    "        \n",
    "        for feature in (gender, number, article):\n",
    "            if feature:\n",
    "                gender_number_article += feature\n",
    "            else:\n",
    "                gender_number_article += '-'\n",
    "        \n",
    "        return gender_number_article\n",
    "\n",
    "    pos2features = {'N': {'xpos_type': xpos[:2], 'xpos_gender_number_article': xpos[2:5]},\n",
    "                    'A': {'xpos_type': xpos[:1], 'xpos_gender_number_article': xpos[1:4]},\n",
    "                    'H': {'xpos_type': xpos[:1], 'xpos_gender_number_article': xpos[1:4]},\n",
    "                    'M': {'xpos_type': xpos[:2], 'xpos_gender_number_article': xpos[2:5]},\n",
    "                    'V': {'xpos_type': xpos[:2],\n",
    "                          'xpos_gender_number_article': gender_number_article(xpos[8:9], xpos[9:10], xpos[10:11])},\n",
    "                    'P': {'xpos_type': xpos[:2],\n",
    "                          'xpos_gender_number_article': gender_number_article(xpos[5:6], xpos[7:8], xpos[8:9])},\n",
    "                    'D': {'xpos_type': xpos},\n",
    "                    'C': {'xpos_type': xpos},\n",
    "                    'T': {'xpos_type': xpos},\n",
    "                    'R': {'xpos_type': xpos},\n",
    "                    'I': {'xpos_type': xpos}}\n",
    "    \n",
    "    result_pos2features = pos2features.get(xpos[0], {'xpos_type': xpos})\n",
    "    \n",
    "    if xpos[0] == 'V' and xpos[4:5] in ('z', 'c', 'g'):\n",
    "        result_pos2features.update({'xpos_mood': xpos[4:5]})\n",
    "    elif xpos[0] == 'P' and xpos[2:3] in ('e', 'a', 'l', 'm', 'q', 't'):\n",
    "        result_pos2features.update({'xpos_ref_type': xpos[2:3]})\n",
    "    elif xpos[0] == 'A' and xpos[4:5] == 'e':\n",
    "        result_pos2features.update({'xpos_extended': xpos[4:5]})\n",
    "    \n",
    "    return {(word + '_' + key): value.rstrip('-') for key, value in result_pos2features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4736b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries) and an index of a word (dictionary)\n",
    "# output - list of dictionaries (features, for each word)\n",
    "def word2features_old(sentence, i):\n",
    "    sentence_contains_interrogative_word = contains_interrogative_word(sentence)\n",
    "    sentence_contains_interrogative_particle = contains_interrogative_particle(sentence)\n",
    "    sentence_contains_imperative_verb = contains_imperative_verb(sentence)\n",
    "    sentence_contains_repetitive_word_before, repetitive_word_tag = contains_repetitive_word_before(sentence, i)\n",
    "\n",
    "    features = {\n",
    "        'word': sentence[i]['text'],\n",
    "        'sent_len': len(sentence),\n",
    "        'upos': sentence[i]['upos'],\n",
    "        'xpos': sentence[i]['xpos'],\n",
    "        'first_word_in_sent': sentence[0]['text'],\n",
    "        'contains_interrogative_word': sentence_contains_interrogative_word,\n",
    "        'contains_interrogative_particle': sentence_contains_interrogative_particle,\n",
    "        'contains_imperative_verb': sentence_contains_imperative_verb,\n",
    "        'starts_with_capital_letter': sentence[i]['text'][0].isupper(),\n",
    "        'contains_repetitive_word_before': sentence_contains_repetitive_word_before,\n",
    "        'repetitive_word_tag': repetitive_word_tag\n",
    "    }\n",
    "\n",
    "    if i > 0:\n",
    "        features.update({\n",
    "            'prev_word': sentence[i-1]['text'],\n",
    "            'prev_word_upos': sentence[i-1]['upos'],\n",
    "            'prev_word_xpos': sentence[i-1]['xpos'],\n",
    "            'prev_word_starts_with_capital_letter': sentence[i-1]['text'][0].isupper()\n",
    "        })\n",
    "    else:\n",
    "        features.update({\n",
    "            'BOS': True\n",
    "        })\n",
    "\n",
    "    if i > 1:\n",
    "        features.update({\n",
    "            'word_before_prev_word': sentence[i-2]['text'],\n",
    "            'word_before_prev_word_upos': sentence[i-2]['upos'],\n",
    "            'word_before_prev_word_xpos': sentence[i-2]['xpos'],\n",
    "            'word_before_prev_word_starts_with_capital_letter': sentence[i-2]['text'][0].isupper()\n",
    "        })\n",
    "\n",
    "    if i < len(sentence)-1:\n",
    "        features.update({\n",
    "            'next_word': sentence[i+1]['text'],\n",
    "            'next_word_upos': sentence[i+1]['upos'],\n",
    "            'next_word_xpos': sentence[i+1]['xpos'],\n",
    "            'next_word_starts_with_capital_letter': sentence[i+1]['text'][0].isupper()\n",
    "        })\n",
    "    else:\n",
    "        features.update({\n",
    "            'EOS': True\n",
    "        })\n",
    "        \n",
    "    if i < len(sentence)-2:\n",
    "        features.update({\n",
    "            'word_after_next_word': sentence [i+2]['text'],\n",
    "            'word_after_next_word_upos': sentence[i+2]['upos'],\n",
    "            'word_after_next_word_xpos': sentence[i+2]['xpos'],\n",
    "            'word_after_next_word_starts_with_capital_letter': sentence[i+2]['text'][0].isupper()\n",
    "        })\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8e923f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries) and an index of a word (dictionary)\n",
    "# output - list of dictionaries (features, for each word)\n",
    "def word2features_old2(sentence, i):\n",
    "    sentence_contains_interrogative_word = contains_interrogative_word(sentence)\n",
    "    sentence_contains_interrogative_particle = contains_interrogative_particle(sentence)\n",
    "    sentence_contains_imperative_verb = contains_imperative_verb(sentence)\n",
    "    sentence_contains_repetitive_word_before, repetitive_word_tag = contains_repetitive_word_before(sentence, i)\n",
    "    sentence_contains_relative_pronoun_before, pronoun_tag = contains_relative_pronoun_before(sentence, i)\n",
    "    sentence_contains_conjunction_before, conjunction_tag = contains_conj_before(sentence, i)\n",
    "    verbs_before = count_of_verbs_before(sentence, i)\n",
    "\n",
    "    features = {\n",
    "        'word': sentence[i]['text'].lower(),\n",
    "        'sent_len': len(sentence),\n",
    "        'upos': sentence[i]['upos'],\n",
    "        'xpos': sentence[i]['xpos'],\n",
    "        'first_word_in_sent': sentence[0]['text'].lower(),\n",
    "        'contains_interrogative_word': sentence_contains_interrogative_word,\n",
    "        'contains_interrogative_particle': sentence_contains_interrogative_particle,\n",
    "        'contains_imperative_verb': sentence_contains_imperative_verb,\n",
    "        'contains_repetitive_word_before': sentence_contains_repetitive_word_before,\n",
    "        'repetitive_word_tag': repetitive_word_tag,\n",
    "        'contains_relative_pronoun_before': sentence_contains_relative_pronoun_before,\n",
    "        'pronoun_tag': pronoun_tag,\n",
    "        'contains_conjunction_before': sentence_contains_conjunction_before,\n",
    "        'conjunction_tag': conjunction_tag,\n",
    "        'count_of_verbs_before': verbs_before\n",
    "    }\n",
    "\n",
    "    if i > 0:\n",
    "        features.update({\n",
    "            'prev_word': sentence[i-1]['text'].lower(),\n",
    "            'prev_word_upos': sentence[i-1]['upos'],\n",
    "            'prev_word_xpos': sentence[i-1]['xpos']\n",
    "        })\n",
    "    else:\n",
    "        features.update({\n",
    "            'BOS': True\n",
    "        })\n",
    "\n",
    "    if i > 1:\n",
    "        features.update({\n",
    "            'word_before_prev_word': sentence[i-2]['text'].lower(),\n",
    "            'word_before_prev_word_upos': sentence[i-2]['upos'],\n",
    "            'word_before_prev_word_xpos': sentence[i-2]['xpos']\n",
    "        })\n",
    "\n",
    "    if i < len(sentence)-1:\n",
    "        features.update({\n",
    "            'next_word': sentence[i+1]['text'].lower(),\n",
    "            'next_word_upos': sentence[i+1]['upos'],\n",
    "            'next_word_xpos': sentence[i+1]['xpos']\n",
    "        })\n",
    "    else:\n",
    "        features.update({\n",
    "            'EOS': True\n",
    "        })\n",
    "        \n",
    "    if i < len(sentence)-2:\n",
    "        features.update({\n",
    "            'word_after_next_word': sentence [i+2]['text'].lower(),\n",
    "            'word_after_next_word_upos': sentence[i+2]['upos'],\n",
    "            'word_after_next_word_xpos': sentence[i+2]['xpos']\n",
    "        })\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "177d6a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries) and an index of a word (dictionary)\n",
    "# output - list of dictionaries (features, for each word)\n",
    "def word2features(sentence, i):\n",
    "    sentence_contains_interrogative_word = contains_interrogative_word(sentence)\n",
    "    sentence_contains_interrogative_particle = contains_interrogative_particle(sentence)\n",
    "    sentence_contains_imperative_verb = contains_imperative_verb(sentence)\n",
    "    sentence_contains_repetitive_word_before, repetitive_word_tag = contains_repetitive_word_before(sentence, i)\n",
    "\n",
    "    features = {\n",
    "        'word': sentence[i]['text'].lower(),\n",
    "        'sent_len': len(sentence),\n",
    "        'upos': sentence[i]['upos'],\n",
    "        'first_word_in_sent': sentence[0]['text'].lower(),\n",
    "        'contains_interrogative_word': sentence_contains_interrogative_word,\n",
    "        'contains_interrogative_particle': sentence_contains_interrogative_particle,\n",
    "        'contains_imperative_verb': sentence_contains_imperative_verb,\n",
    "        'contains_repetitive_word_before': sentence_contains_repetitive_word_before,\n",
    "        'repetitive_word_tag': repetitive_word_tag\n",
    "    }\n",
    "\n",
    "    features.update(split_xpos(sentence[i]['xpos']))\n",
    "\n",
    "    if i > 0:\n",
    "        features.update({\n",
    "            'prev_word': sentence[i-1]['text'].lower(),\n",
    "            'prev_word_upos': sentence[i-1]['upos']\n",
    "        })\n",
    "\n",
    "        features.update(split_xpos(sentence[i-1]['xpos'], 'prev_word'))\n",
    "    else:\n",
    "        features.update({\n",
    "            'BOS': True\n",
    "        })\n",
    "\n",
    "    if i > 1:\n",
    "        features.update({\n",
    "            'word_before_prev_word': sentence[i-2]['text'].lower(),\n",
    "            'word_before_prev_word_upos': sentence[i-2]['upos']\n",
    "        })\n",
    "        \n",
    "        features.update(split_xpos(sentence[i-2]['xpos'], 'word_before_prev_word'))\n",
    "\n",
    "    if i < len(sentence)-1:\n",
    "        features.update({\n",
    "            'next_word': sentence[i+1]['text'].lower(),\n",
    "            'next_word_upos': sentence[i+1]['upos']\n",
    "        })\n",
    "        \n",
    "        features.update(split_xpos(sentence[i+1]['xpos'], 'next_word'))\n",
    "    else:\n",
    "        features.update({\n",
    "            'EOS': True\n",
    "        })\n",
    "        \n",
    "    if i < len(sentence)-2:\n",
    "        features.update({\n",
    "            'word_after_next_word': sentence [i+2]['text'].lower(),\n",
    "            'word_after_next_word_upos': sentence[i+2]['upos']\n",
    "        })\n",
    "        \n",
    "        features.update(split_xpos(sentence[i+2]['xpos'], 'word_after_next_word'))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b37c7123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries)\n",
    "# output - list of features (dictionaries, for each word)\n",
    "def sent2features(sentence):\n",
    "    return [word2features(sentence, i) for i in range(len(sentence))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3eefcddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - JSON-serializable data and name of the output JSON file\n",
    "# output - None, saves the sentences to a JSON file\n",
    "def save_as_json(data, output_file_name):\n",
    "    with open(output_file_name, \"w\") as output_file:\n",
    "        json.dump(data, output_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc90be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - JSON file\n",
    "# output - the contents of the JSON file as an object\n",
    "def load_json(json_file_name):\n",
    "    with open(json_file_name, \"r\") as json_file:\n",
    "        return json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd987f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - name of a text file with one sentence per line and a variable indicating whether or not to save X and y to JSON\n",
    "# output - X and y - features and labels\n",
    "def data_prep(input_file_name, json_serialize=False):\n",
    "    data = read_file_as_list_of_sentences(input_file_name)\n",
    "    nlp_tokenize = classla.Pipeline('bg', processors='tokenize')\n",
    "    tokenized_data = run_through_classla_pipeline(data, nlp_tokenize)\n",
    "    \n",
    "    if len(data) != len(tokenized_data):\n",
    "        print(\"Warning: Mismatch in the count of the data and tokenized data\")\n",
    "\n",
    "    squashed_tokenized_data = [squash_punctuation(sentence) for sentence in tokenized_data]\n",
    "\n",
    "    if len(tokenized_data) != len(squashed_tokenized_data):\n",
    "        print(\"Warning: Mismatch in the count of the tokenized and squashed tokenized data\")\n",
    "    \n",
    "    y = [sent2labels(sentence) for sentence in squashed_tokenized_data]\n",
    "    \n",
    "    if len(squashed_tokenized_data) != len(y):\n",
    "        print(\"Warning: Mismatch in the count of the squashed tokenized data and labeled data\")\n",
    "    \n",
    "    data_without_punctuation = [remove_punctuation(sentence) for sentence in squashed_tokenized_data]\n",
    "    \n",
    "    if len(data_without_punctuation) != len(y):\n",
    "        print(\"Warning: Mismatch in the count of the data without punctuation and labeled data\")\n",
    "    \n",
    "    nlp_pos_tokenize = classla.Pipeline('bg', processors='tokenize,pos')   \n",
    "    pos_tokenized_data = run_through_classla_pipeline(data_without_punctuation, nlp_pos_tokenize)\n",
    "    \n",
    "    if len(data_without_punctuation) != len(pos_tokenized_data):\n",
    "        print(\"Warning: Mismatch in the count of the data without punctuation and POS tokenized data\")\n",
    "    \n",
    "    X = [sent2features(sentence) for sentence in pos_tokenized_data]\n",
    "    \n",
    "    if len(X) != len(pos_tokenized_data):\n",
    "        print(\"Warning: Mismatch in the count of the prepped data and POS tokenized data\")\n",
    "    \n",
    "    if json_serialize:\n",
    "        save_as_json(X, re.sub('\\.txt', '_X.json', input_file_name))\n",
    "        save_as_json(y, re.sub('\\.txt', '_y.json', input_file_name))\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7608e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - X and y - features and labels\n",
    "# output - None, prints on the screen the features-labels pairs that have length mismatch\n",
    "def verify_prepped_data(X, y):\n",
    "    for feat, label in zip(X, y):\n",
    "        if len(feat) != len(label):\n",
    "            print(feat, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e592e21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - X and y - features and labels\n",
    "# output - list of punctuated sentences (strings; y labels applied to X)\n",
    "def punctuate(X, y):\n",
    "    punctuated_sentences = []\n",
    "\n",
    "    for feat, label in zip(X, y):\n",
    "        sentence = ''\n",
    "\n",
    "        for i in range(len(feat)):\n",
    "            sentence = sentence + feat[i]['word'] + label[i] + ' '\n",
    "        \n",
    "        punctuated_sentences.append(sentence.rstrip())\n",
    "    \n",
    "    return punctuated_sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
