{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "import classla\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a6483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - name of a text file with one sentence per line\n",
    "# output - list of sentences (strings)\n",
    "def read_file_as_list_of_sentences(input_file_name):\n",
    "    with open(input_file_name, \"r\") as input_file:\n",
    "        return input_file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a74497",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_pos_tokenize = classla.Pipeline('bg', processors='tokenize,pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5146176",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tokenize = classla.Pipeline('bg', processors='tokenize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - list of sentences (strings) and a classla pipeline (POS tokenize or tokenize)\n",
    "# output - list of dictionaries ((POS) tokenized sentences) \n",
    "def run_through_classla_pipeline(list_of_sentences, pipeline):\n",
    "    return [pipeline(sentence).to_dict()[0][0] for sentence in list_of_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - list of dictionaries (a dictionary for each word - the tokenized version of the sentence)\n",
    "# output - list of dictionaries (dictionaries that contain punctuation one after another are squashed into one)\n",
    "def squash_punctuation(sentence):\n",
    "    new_sentence = []\n",
    "\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i]['text'] in ',()\"[];.?!:-':\n",
    "            if len(new_sentence) > 0 and all(character in ',()\"[];.?!:-' for character in new_sentence[-1]['text']):\n",
    "                new_sentence[-1]['text'] += sentence[i]['text']\n",
    "            else:\n",
    "                new_sentence.append(sentence[i])\n",
    "        else:\n",
    "            new_sentence.append(sentence[i])\n",
    "            \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence and an index of a word (dictionary) - assigns a label to each word based on the punctuation after\n",
    "# output - a label - None for punctuation, punctuation for words followed by punctuation and empty for words if they are not\n",
    "def word2label(sentence, i):\n",
    "    if all(character in ',()\"[];.?!:-' for character in sentence[i]['text']):\n",
    "        return None\n",
    "\n",
    "    if i < len(sentence) - 1:\n",
    "        if all(character in ',()\"[];.?!:-' for character in sentence[i+1]['text']):\n",
    "            label = sentence[i+1]['text']\n",
    "            return label\n",
    "    \n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed05a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries)\n",
    "# output - list of labels (strings) with None labels for punctuation being filtered out\n",
    "def sent2labels(sentence):\n",
    "    return [label for label in (word2label(sentence, i) for i in range(len(sentence))) if label != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - list of dictionaries (a dictionary for each word - the tokenized version of the sentence)\n",
    "# output - new sentence (string) with the punctuation removed\n",
    "def remove_punctuation(sentence):\n",
    "    new_sentence = ''\n",
    "\n",
    "    for i in range(len(sentence)):\n",
    "        if all(character not in ',()\"[];.?!:-' for character in sentence[i]['text']):\n",
    "            new_sentence = new_sentence + sentence[i]['text'] + ' '\n",
    "    \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries) and an index of a word (dictionary)\n",
    "# output - list of dictionaries (features, for each word)\n",
    "def word2features(sentence, i):\n",
    "    features = {\n",
    "        'word': sentence[i]['text'],\n",
    "        'sent_len': len(sentence),\n",
    "        'pos_in_sent': i,\n",
    "        'upos': sentence[i]['upos'],\n",
    "        'xpos': sentence[i]['xpos'],\n",
    "        'first_word_in_sent': sentence[0]['text']\n",
    "    }\n",
    "\n",
    "    if i > 0:\n",
    "        features.update({\n",
    "            'prev_word': sentence[i-1]['text']\n",
    "        })\n",
    "    else:\n",
    "        features.update({\n",
    "            'BOS': True\n",
    "        })\n",
    "\n",
    "    if i < len(sentence)-1:\n",
    "        features.update({\n",
    "            'next_word': sentence[i+1]['text']\n",
    "        })\n",
    "    else:\n",
    "        features.update({\n",
    "            'EOS': True\n",
    "        })\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a093df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - sentence (list of dictionaries)\n",
    "# output - list of features (dictionaries, for each word)\n",
    "def sent2features(sentence):\n",
    "    return [word2features(sentence, i) for i in range(len(sentence))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f67be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - a list of lists of dictionaries ((POS) tokenized sentences) and name of the output JSON file\n",
    "# output - None, saves the sentences to a JSON file\n",
    "def save_pos_tokenized_sentences_as_json(pos_tokenized_sentences, output_file_name):\n",
    "    with open(output_file_name, \"w\") as output_file:\n",
    "        json.dump(pos_tokenized_sentences, output_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaacfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'И ще изкараш ли виновен Праведния и Могъщия, който казва на цар: Негоден си. - и на княз: Беззаконник. - който пристрастие към първенци не показва, нито зачита богатия повече от бедния, понеже всички те са дело на ръцете Му!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74abb740",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = run_through_classla_pipeline([sentence], nlp_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03171e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7828ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "squashed_sent = squash_punctuation(tokenized_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd53cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "squashed_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a29fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2labels(squashed_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6238beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = remove_punctuation(squashed_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfc9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_through_classla_pipeline([new_sentence], nlp_pos_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6807ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  read_file_as_list_of_sentences('../data/Bible/processed/Bibliia_clean_dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5452ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_tokenize = classla.Pipeline('bg', processors='tokenize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da39dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_data = run_through_classla_pipeline(train_data, nlp_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "squashed_tokenized_train_data = [squash_punctuation(sentence) for sentence in tokenized_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [sent2labels(sentence) for sentence in squashed_tokenized_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_without_punctuation = [remove_punctuation(sentence) for sentence in squashed_tokenized_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b77dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_pos_tokenize = classla.Pipeline('bg', processors='tokenize,pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdf582",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tokenized_train_data = run_through_classla_pipeline(train_data_without_punctuation, nlp_pos_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e44625",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(sentence) for sentence in pos_tokenized_train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f9438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in X_train:\n",
    "    for label in y_train:\n",
    "        if len(sentence) != len(label):\n",
    "            print(sentence, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open('../data/Bible/processed/Bibliia_clean_test.json', \"r\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e1b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len([{'word': 'А', 'sent_len': 9, 'pos_in_sent': 0, 'upos': 'CCONJ', 'xpos': 'Cp', 'first_word_in_sent': 'А', 'BOS': True, 'next_word': 'Йоас'}, {'word': 'Йоас', 'sent_len': 9, 'pos_in_sent': 1, 'upos': 'PROPN', 'xpos': 'Hmsi', 'first_word_in_sent': 'А', 'prev_word': 'А', 'next_word': 'беше'}, {'word': 'беше', 'sent_len': 9, 'pos_in_sent': 2, 'upos': 'AUX', 'xpos': 'Vxitf-t3s', 'first_word_in_sent': 'А', 'prev_word': 'Йоас', 'next_word': 'погребан'}, {'word': 'погребан', 'sent_len': 9, 'pos_in_sent': 3, 'upos': 'VERB', 'xpos': 'Vpptcv--smi', 'first_word_in_sent': 'А', 'prev_word': 'беше', 'next_word': 'в'}, {'word': 'в', 'sent_len': 9, 'pos_in_sent': 4, 'upos': 'ADP', 'xpos': 'R', 'first_word_in_sent': 'А', 'prev_word': 'погребан', 'next_word': 'Самария'}, {'word': 'Самария', 'sent_len': 9, 'pos_in_sent': 5, 'upos': 'PROPN', 'xpos': 'Npfsi', 'first_word_in_sent': 'А', 'prev_word': 'в', 'next_word': 'при'}, {'word': 'при', 'sent_len': 9, 'pos_in_sent': 6, 'upos': 'ADP', 'xpos': 'R', 'first_word_in_sent': 'А', 'prev_word': 'Самария', 'next_word': 'израилевите'}, {'word': 'израилевите', 'sent_len': 9, 'pos_in_sent': 7, 'upos': 'ADJ', 'xpos': 'A-pd', 'first_word_in_sent': 'А', 'prev_word': 'при', 'next_word': 'царе'}, {'word': 'царе', 'sent_len': 9, 'pos_in_sent': 8, 'upos': 'NOUN', 'xpos': 'Ncmpi', 'first_word_in_sent': 'А', 'prev_word': 'израилевите', 'EOS': True}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00577c",
   "metadata": {},
   "outputs": [],
   "source": [
    " len(['', '', '', '', ':', '', '', '', '', '', '', '', '', '-', '', '', '', '', '', '', '', '', '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb137fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b811527",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = json.load(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473d0ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = open('../data/Bible/processed/Bibliia_clean_one_sent.json', \"r\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b520e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f3_data = json.load(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be957d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = [sent2features(sent) for sent in data]\n",
    "y_train = [sent2labels(sent) for sent in data]\n",
    "\n",
    "X_test = [sent2features(sent) for sent in test_data]\n",
    "y_test = [sent2labels(sent) for sent in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b055193",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(crf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80536204",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392346a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02934f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
